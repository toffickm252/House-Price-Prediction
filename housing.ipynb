{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5060c8ff",
   "metadata": {},
   "source": [
    "## Housing Price Predictor \n",
    "#### Learning by doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56be67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49fcb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "data = pd.read_csv('C:\\\\Users\\\\Surface\\\\OneDrive\\\\Documentos\\\\GitHub\\\\House-Price-Prediction\\\\data\\\\Housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d626bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
      "0  13300000  7420         4          2        3      yes        no       no   \n",
      "1  12250000  8960         4          4        4      yes        no       no   \n",
      "2  12250000  9960         3          2        2      yes        no      yes   \n",
      "3  12215000  7500         4          2        2      yes        no      yes   \n",
      "4  11410000  7420         4          1        2      yes       yes      yes   \n",
      "\n",
      "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
      "0              no             yes        2      yes        furnished  \n",
      "1              no             yes        3       no        furnished  \n",
      "2              no              no        2      yes   semi-furnished  \n",
      "3              no             yes        3      yes        furnished  \n",
      "4              no             yes        2       no        furnished  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   price             545 non-null    int64 \n",
      " 1   area              545 non-null    int64 \n",
      " 2   bedrooms          545 non-null    int64 \n",
      " 3   bathrooms         545 non-null    int64 \n",
      " 4   stories           545 non-null    int64 \n",
      " 5   mainroad          545 non-null    object\n",
      " 6   guestroom         545 non-null    object\n",
      " 7   basement          545 non-null    object\n",
      " 8   hotwaterheating   545 non-null    object\n",
      " 9   airconditioning   545 non-null    object\n",
      " 10  parking           545 non-null    int64 \n",
      " 11  prefarea          545 non-null    object\n",
      " 12  furnishingstatus  545 non-null    object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 55.5+ KB\n",
      "None\n",
      "              price          area    bedrooms   bathrooms     stories  \\\n",
      "count  5.450000e+02    545.000000  545.000000  545.000000  545.000000   \n",
      "mean   4.766729e+06   5150.541284    2.965138    1.286239    1.805505   \n",
      "std    1.870440e+06   2170.141023    0.738064    0.502470    0.867492   \n",
      "min    1.750000e+06   1650.000000    1.000000    1.000000    1.000000   \n",
      "25%    3.430000e+06   3600.000000    2.000000    1.000000    1.000000   \n",
      "50%    4.340000e+06   4600.000000    3.000000    1.000000    2.000000   \n",
      "75%    5.740000e+06   6360.000000    3.000000    2.000000    2.000000   \n",
      "max    1.330000e+07  16200.000000    6.000000    4.000000    4.000000   \n",
      "\n",
      "          parking  \n",
      "count  545.000000  \n",
      "mean     0.693578  \n",
      "std      0.861586  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      1.000000  \n",
      "max      3.000000  \n"
     ]
    }
   ],
   "source": [
    "# Basic Data Exploration\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65defbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ddc23e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   price             545 non-null    int64 \n",
      " 1   area              545 non-null    int64 \n",
      " 2   bedrooms          545 non-null    int64 \n",
      " 3   bathrooms         545 non-null    int64 \n",
      " 4   stories           545 non-null    int64 \n",
      " 5   mainroad          545 non-null    object\n",
      " 6   guestroom         545 non-null    object\n",
      " 7   basement          545 non-null    object\n",
      " 8   hotwaterheating   545 non-null    object\n",
      " 9   airconditioning   545 non-null    object\n",
      " 10  parking           545 non-null    int64 \n",
      " 11  prefarea          545 non-null    object\n",
      " 12  furnishingstatus  545 non-null    object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 55.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3dee74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "furnishingstatus\n",
      "semi-furnished    227\n",
      "unfurnished       178\n",
      "furnished         140\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['furnishingstatus'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d979bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mainroad\n",
      "yes    468\n",
      "no      77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['mainroad'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01ec63d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surface\\AppData\\Local\\Temp\\ipykernel_14240\\1003500890.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[binary_cols] = data[binary_cols].replace({'yes': 1, 'no': 0})\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding Binary Columns\n",
    "# List the 6 columns that are expected to be 'yes'/'no'\n",
    "binary_cols = ['mainroad', 'guestroom', 'basement', \n",
    "               'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "\n",
    "# Apply the mapping using the Pandas .replace() method\n",
    "data[binary_cols] = data[binary_cols].replace({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7768db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mainroad\n",
      "1    468\n",
      "0     77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['mainroad'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8737cc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(545, 14)\n",
      "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
      "0  13300000  7420         4          2        3         1          0   \n",
      "1  12250000  8960         4          4        4         1          0   \n",
      "2  12250000  9960         3          2        2         1          0   \n",
      "3  12215000  7500         4          2        2         1          0   \n",
      "4  11410000  7420         4          1        2         1          1   \n",
      "\n",
      "   basement  hotwaterheating  airconditioning  parking  prefarea  \\\n",
      "0         0                0                1        2         1   \n",
      "1         0                0                1        3         0   \n",
      "2         1                0                0        2         1   \n",
      "3         1                0                1        3         1   \n",
      "4         1                0                1        2         0   \n",
      "\n",
      "   furnishingstatus_semi-furnished  furnishingstatus_unfurnished  \n",
      "0                                0                             0  \n",
      "1                                0                             0  \n",
      "2                                1                             0  \n",
      "3                                0                             0  \n",
      "4                                0                             0  \n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding the Multiclass Column\n",
    "# Apply One-Hot Encoding to the 'furnishingstatus' column\n",
    "# drop_first=True is used to avoid multicollinearity\n",
    "df = pd.get_dummies(data, columns=['furnishingstatus'], drop_first=True, dtype=int)\n",
    "data = df.copy()\n",
    "# Check the new shape and the new column names\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d11e82f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (Features): (545, 13)\n",
      "Shape of y (Target): (545,)\n"
     ]
    }
   ],
   "source": [
    "# Preparing Data for the Mode\n",
    "# Create the target variable (y) - the variable we want to predict\n",
    "y = df['price']\n",
    "\n",
    "# Create the feature matrix (X) by dropping the target column\n",
    "# axis=1 specifies that we are dropping a column\n",
    "X = df.drop('price', axis=1)\n",
    "\n",
    "# Check the shapes to confirm\n",
    "print(\"Shape of X (Features):\", X.shape)\n",
    "print(\"Shape of y (Target):\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "399f5862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (381, 13)\n",
      "X_test shape: (164, 13)\n",
      "y_train shape: (381,)\n",
      "y_test shape: (164,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Note: random_state=42 ensures the split is the same every time you run the code.\n",
    "\n",
    "# Check the shapes to confirm the split\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "168ba728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers removed from training set.\n",
      "New X_train shape: (371, 13)\n"
     ]
    }
   ],
   "source": [
    "# --- INSERT THIS CODE AFTER train_test_split AND BEFORE StandardScaler ---\n",
    "\n",
    "# 1. Calculate the necessary statistical quartiles\n",
    "Q1 = y_train.quantile(0.25)\n",
    "Q3 = y_train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the upper boundary (1.5 * IQR is the standard outlier definition)\n",
    "upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "# 2. Filter the training data to remove prices above the limit\n",
    "# We create a new, filtered y_train\n",
    "y_train_filtered = y_train[y_train < upper_limit]\n",
    "\n",
    "# We must use the exact same index from the filtered target variable \n",
    "# to filter the corresponding rows from the feature matrix (X_train)\n",
    "X_train_filtered = X_train.loc[y_train_filtered.index]\n",
    "\n",
    "# Finally, update the variables to the new, filtered data\n",
    "y_train = y_train_filtered\n",
    "X_train = X_train_filtered\n",
    "\n",
    "print(\"Outliers removed from training set.\")\n",
    "print(f\"New X_train shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d45b8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (371, 13)\n",
      "X_test_scaled shape: (164, 13)\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling: Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 1. Fit the scaler ONLY on the training data (X_train) and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 2. Transform the test data using the fitted scaler (DO NOT re-fit)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "348e12e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variables successfully log-transformed.\n"
     ]
    }
   ],
   "source": [
    "# Create new log-transformed target variables\n",
    "y_train= np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "print(\"Target variables successfully log-transformed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30c6565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Complete.\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "# Initialize the Linear Regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Train the model using the scaled training data (X_train_scaled) \n",
    "# and the target prices (y_train)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c1208a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions generated and stored in 'y_pred'.\n"
     ]
    }
   ],
   "source": [
    "# Model Prediction\n",
    "# Generate predictions for the unseen test data\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "print(\"Predictions generated and stored in 'y_pred'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47b587ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared Score: 0.6570669612998578\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate the R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4a16e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.19063495643222306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6be9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 0.2439033204531407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np \n",
    "\n",
    "# 1. Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# 2. Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac2cbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter Tuning with GridSearchCV\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # parameter grid dictionary\n",
    "# param_grid = {\n",
    "#     'alpha': [0.01, 0.1, 1.0, 10.0, 100.0] \n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bec567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initializing the Model\n",
    "# ridge = Ridge()\n",
    "\n",
    "# # Setting up GridSearchCV\n",
    "# #grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid, \n",
    "# #                           scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "\n",
    "# ridge_tuner = GridSearchCV(\n",
    "#     estimator=ridge,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7509049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter Tuning with Grid Search\n",
    "# # Start the search process: Grid Search will train 5 models for each of the 5 alpha values.\n",
    "# ridge_tuner.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31d3ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the best alpha value and its score\n",
    "# print(f\"Best Hyperparameters (alpha): {ridge_tuner.best_params_}\")\n",
    "# print(f\"Best Cross-Validation Score (R^2): {ridge_tuner.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc9e9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ned_log = best_ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# # 3. CRITICAL: Reverse transformation to get prices in currency\n",
    "# y_pred_tuned = np.exp(y_pred_tuned_log) \n",
    "\n",
    "# # 4. Calculate Final Metrics (Comparing original y_test to reversed y_pred_tuned)\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "# import numpy as np\n",
    "\n",
    "# r2_final = r2_score(y_test, y_pred_tuned)\n",
    "# rmse_final = np.sqrt(mean_squared_error(y_test, y_pred_tuned))\n",
    "\n",
    "# print(f\"Final R-squared Score (Tuned Model): {r2_final}\")\n",
    "# print(f\"Final RMSE (Tuned Mo# 1. Select the best model\n",
    "# best_ridge_model = ridge_tuner.best_estimator_\n",
    "\n",
    "# # 2. Predict prices (output is in log units)\n",
    "# y_pred_tudel): {rmse_final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cba0fad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['house_price_model.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(lr, 'house_price_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41162802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_transform.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, 'scaler_transform.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
